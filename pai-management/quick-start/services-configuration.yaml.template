# Copyright (c) Microsoft Corporation
# All rights reserved.
#
# MIT License
#
# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
# documentation files (the "Software"), to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and
# to permit persons to whom the Software is furnished to do so, subject to the following conditions:
# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED *AS IS*, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
# BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
# DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

cluster:

  clusterid: pai-example

  # HDFS, zookeeper data path on your cluster machine.
  data-path: "/datastorage"

  # the docker registry to store docker images that contain system services like frameworklauncher, hadoop, etc.
  docker-registry-info:

    # If public, please fill it the same as your username
    docker-namespace: openpai

    # E.g., gcr.io. If public, fill docker_registry_domain with word "public"
    # docker_registry_domain: public
    docker-registry-domain: docker.io
    # If the docker registry doesn't require authentication, please leave docker_username and docker_password empty
    #docker-username: <username>
    #docker-password: <password>

    docker-tag: latest

    # The name of the secret in kubernetes will be created in your cluster
    # Must be lower case, e.g., regsecret.
    secret-name: pai-secret


hadoop:
  # When needed, hadoop-ai would be downloaded and built under 'custom-hadoop-binary-path'.
  # More about hadoop-ai please follow the link: https://github.com/Microsoft/pai/tree/master/hadoop-ai.
  # Notice: the name should be hadoop-{hadoop-version}.tar.gz
  custom-hadoop-binary-path: /pathHadoop/hadoop-2.9.0.tar.gz
  hadoop-version: 2.9.0
  # Step 1 of 4 to set up Hadoop queues.
  # Define all virtual clusters, equivalent concept of Hadoop queues:
  #   - Each VC will be assigned with (capacity / total_capacity * 100%) of the resources in the system.
  #   - The 'default' VC can be used by any PAI user, i.e. a user will be automatically put into the
  #     member list of 'default' VC when it is created.
  #   - The system will automatically create the 'default' VC with 0 capacity, if 'default' VC has not
  #     been explicitly specified here.
  #virtualClusters:
  #  default:
  #    description: Default VC.
  #    capacity: 40
  #  vc1:
  #    description: VC for Alice's team.
  #    capacity: 20
  #  vc2:
  #    description: VC for Bob's team.
  #    capacity: 20
  #  vc3:
  #    description: VC for Charlie's team.
  #    capacity: 20


frameworklauncher:
  frameworklauncher-port: 9086


restserver:
  # port for rest api server
  server-port: 9186
  # secret for signing authentication tokens, e.g., "Hello PAI!"
  jwt-secret: pai-secret
  # database admin username
  default-pai-admin-username: admin
  # database admin password
  default-pai-admin-password: admin-password


webportal:
  # port for webportal
  server-port: 9286


grafana:
  # port for grafana
  grafana-port: 3000



prometheus:
  # port for prometheus port
  prometheus-port: 9091
  # port for node exporter
  node-exporter-port: 9100
  # How frequently to scrape targets
  scrape_interval: 30


pylon:
  # port of pylon
  port: 80
